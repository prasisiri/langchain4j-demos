# Server configuration
server.port=8080

# GitHub Models configuration
langchain4j.github.token=demo
langchain4j.github.model=gpt-4o-mini
langchain4j.github.temperature=0.7
langchain4j.github.timeout=60s

# Chat memory configuration
langchain4j.chat.memory.max-messages=10

# Logging configuration
logging.level.dev.langchain4j=INFO
logging.level.com.example=INFO